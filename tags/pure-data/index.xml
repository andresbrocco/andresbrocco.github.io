<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pure Data on Andre Sbrocco Figueiredo</title>
    <link>https://andresbrocco.com/tags/pure-data/</link>
    <description>Recent content in Pure Data on Andre Sbrocco Figueiredo</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>=&amp;copy; 2020</copyright>
    <lastBuildDate>Wed, 27 Feb 2019 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://andresbrocco.com/tags/pure-data/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Chroma Jammer</title>
      <link>https://andresbrocco.com/project/chroma-jammer/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://andresbrocco.com/project/chroma-jammer/</guid>
      <description>&lt;p&gt;ChromaJammer is personal project of a music visualization tool that &amp;ldquo;forces&amp;rdquo; synesthesia by associating colors with notes. The main goal is to assist the music learning process, by attaching vision and audition.&lt;/p&gt;
&lt;p&gt;The ChromaJammer was written in the &lt;!-- raw HTML omitted --&gt;PureData&lt;!-- raw HTML omitted --&gt; programming language. The patch gets the audio from an external source (mic or music player) and analyses which notes are being played. Each note has an associated color. The color scheme was based on the circle of fifths, since it arranges the notes in an interesting manner: the interval between adjacent notes is the most consonant possible. The circle of fifths is drawn alongside a representation of a guitar arm. When a note is identified, its respective frets lights up on the guitar arm.&lt;/p&gt;
&lt;p&gt;As an amateur musician, I&amp;rsquo;ve always wanted to improvise on the guitar, but struggled in learning music theory. On the other hand, I found myself with the right knowledge to develop a tool to enhance my capabilities. The project is open-source and can be downloaded from my &lt;!-- raw HTML omitted --&gt;GitHub repository&lt;!-- raw HTML omitted --&gt;. I hope more people enjoy the tool, and maybe some day I&amp;rsquo;ll go back to this project.&lt;/p&gt;
&lt;p&gt;I have made a video presenting the patch and showing it in action!&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Medooze</title>
      <link>https://andresbrocco.com/project/medooze/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://andresbrocco.com/project/medooze/</guid>
      <description>&lt;p&gt;Medooze is a personal project developed by me and Gabriela Bittencourt, consisting of a smart lighting system. The algorithm developed by us analyses the music in real time to create synesthetic visual effects.&lt;/p&gt;
&lt;p&gt;The installation was presented in a music festival: the audio from the DJ mixer was captured by an audio interface, and processed in a Pure Data patch. This patch simulated a fluid that was reacting to several audio features in real time.&lt;/p&gt;
&lt;p&gt;The fluid positions were then mapped to a color palette, forming visual streams in a wave-like motion. Each particle of the fluid was then mapped to a corresponding Led in a strip. This information was sent through the network to a Raspberry Pi, which controlled 12 Led Strips.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;A total of 60m of Led Strips were placed above the dance floor, streaming out from the DJ cabine, represented as an hexagon in the video. You can see the infrastructure in the pictures below.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
  </channel>
</rss>
